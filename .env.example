# =============================================================================
# DOCU-GEN Environment Configuration Template
# =============================================================================
# Copy this file to .env and fill in your actual values
# cp .env.example .env

# -----------------------------------------------------------------------------
# Environment Mode
# -----------------------------------------------------------------------------
# Options: dev, prod, test
ENVIRONMENT=dev

# -----------------------------------------------------------------------------
# LLM Provider Configuration
# -----------------------------------------------------------------------------
# Choose your LLM provider: gemini, openai, or ollama
LLM_PROVIDER=ollama

# -----------------------------------------------------------------------------
# Ollama Configuration (for local LLM)
# -----------------------------------------------------------------------------
# Default model to use (e.g., dolphin3, mixtral, etc.)
OLLAMA_DEFAULT_MODEL=dolphin3

# Ollama API base URL
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MAX_TOKENS=8192

# Ollama request timeout (in seconds)
# Increase for large models or long document generation
# Default: 600 (10 minutes), recommended: 600-1800 for complex docs
OLLAMA_TIMEOUT=600      # Request timeout in seconds (10 minutes)
# OLLAMA_TIMEOUT=1800   # For very long documents (30 minutes)

# Ollama Phase Model Configuration (Optional - Advanced)
# Configure different models for different phases to balance speed and quality
# Phase 1: Fast decision documents (requirements, business_model, marketing_plan)
# Phase 2: High-quality technical documents (technical_doc, database_schema)
# Phase 3: High-quality API/dev documents (api_doc, dev_doc, test_doc)
# Phase 4: User/support documents (user_doc, pm_doc, support_playbook)
# OLLAMA_PHASE1_MODEL=dolphin3    # Fast model for Phase 1
# OLLAMA_PHASE2_MODEL=mixtral     # High-quality model for Phase 2
# OLLAMA_PHASE3_MODEL=mixtral     # High-quality model for Phase 3
# OLLAMA_PHASE4_MODEL=dolphin3    # Fast model for Phase 4

# -----------------------------------------------------------------------------
# Gemini Configuration (Google)
# -----------------------------------------------------------------------------
# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# Default Gemini model
GEMINI_DEFAULT_MODEL=gemini-2.0-flash

# Gemini Phase Model Configuration (Optional - Advanced)
# Configure different models for different phases to balance speed and cost
# Phase 1: Fast models with high free quota (gemini-2.0-flash)
# Phase 2+: High-quality models (gemini-2.0-pro)
# GEMINI_PHASE1_MODEL=gemini-2.0-flash  # Fast, high free quota
# GEMINI_PHASE2_MODEL=gemini-2.0-pro    # High quality
# GEMINI_PHASE3_MODEL=gemini-2.0-pro    # High quality
# GEMINI_PHASE4_MODEL=gemini-2.0-flash  # Fast, high free quota

# -----------------------------------------------------------------------------
# OpenAI Configuration
# -----------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Default OpenAI model
OPENAI_DEFAULT_MODEL=gpt-4o-mini

# OpenAI Phase Model Configuration (Optional - Advanced)
# Configure different models for different phases to balance speed and cost
# Phase 1: Low-cost models (gpt-4o-mini)
# Phase 2+: High-quality models (gpt-4o)
# OPENAI_PHASE1_MODEL=gpt-4o-mini  # Low cost, fast
# OPENAI_PHASE2_MODEL=gpt-4o       # High quality
# OPENAI_PHASE3_MODEL=gpt-4o       # High quality
# OPENAI_PHASE4_MODEL=gpt-4o-mini  # Low cost, fast

# Temperature Configuration
# Default temperature for all providers (lower for better instruction following)
TEMPERATURE=0.3

# Provider-specific temperature overrides
OLLAMA_TEMPERATURE=0.3      # Lower for local models (better instruction following)
GEMINI_TEMPERATURE=0.7      # Higher for cloud models (balanced)
OPENAI_TEMPERATURE=0.7      # Higher for cloud models (balanced)

# Document Summary Configuration
# Maximum length for document summaries (in characters)
# Increase for longer documents, decrease for shorter summaries
MAX_SUMMARY_LENGTH=3000      # Default: 3000 chars (increased from 2000 for better coverage)

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------
LOG_LEVEL=DEBUG
LOG_FORMAT=text
LOG_DIR=logs

# -----------------------------------------------------------------------------
# Application Configuration
# -----------------------------------------------------------------------------
DOCS_DIR=docs
RATE_LIMIT_PER_MINUTE=60
